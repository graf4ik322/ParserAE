#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import requests
from bs4 import BeautifulSoup
import json
import re
import time
import logging
from typing import List, Dict, Optional, Tuple
from urllib.parse import urljoin, urlparse
from datetime import datetime

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('enhanced_parser.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class EnhancedFactoryParser:
    def __init__(self):
        self.base_url = "https://aroma-euro.ru"
        self.session = requests.Session()
        # –£–±–∏—Ä–∞–µ–º Accept-Encoding –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø—Ä–æ–±–ª–µ–º —Å —Å–∂–∞—Ç–∏–µ–º
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        })
        self.perfumes = []
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ —Ñ–∞–±—Ä–∏–∫–∏
        self.known_factories = [
            'Bin Tammam', 'EPS', 'Givaudan', 'Givaudan Premium', 'Hamidi', 
            'Iberchem', 'LZ AG', 'Lz', 'LZ', 'MG Gulcicek', 'Reiha', 
            'Argeville', 'SELUZ', 'Seluz', 'LUZI', 'Luzi'
        ]
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –¥–ª—è –ª—É—á—à–µ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        self.known_brands = [
            'Tom Ford', 'Chanel', 'Dior', 'Christian Dior', 'Creed', 'Amouage',
            'Maison Francis Kurkdjian', 'Byredo', 'Le Labo', 'Escentric Molecules',
            'Tiziana Terenzi', 'Ex Nihilo', 'Nasomatto', 'Orto Parisi',
            'Giorgio Armani', 'Versace', 'Gucci', 'Prada', 'Yves Saint Laurent',
            'Givenchy', 'Herm√®s', 'Bulgari', 'Dolce&Gabbana', 'Paco Rabanne',
            'Lacoste', 'Hugo Boss', 'Calvin Klein', 'Antonio Banderas',
            'Lanvin', 'Attar Collection', 'Marc-Antoine Barrois', 'Ajmal',
            'Victoria\'s Secret', 'Thomas Kosmala'
        ]

    def get_page_content(self, url: str) -> Optional[BeautifulSoup]:
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏"""
        try:
            response = self.session.get(url, timeout=30, stream=True)
            response.raise_for_status()
            
            # –ü–æ–ª—É—á–∞–µ–º —Å—ã—Ä–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
            content = response.content
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Å —É—á–µ—Ç–æ–º –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            if response.encoding:
                text = content.decode(response.encoding)
            else:
                text = content.decode('utf-8', errors='ignore')
            
            logger.info(f"–†–∞–∑–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ 'product-title' –≤ HTML: {text.count('product-title')}")
            
            return BeautifulSoup(text, 'html.parser')
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")
            return None

    def extract_factory_info(self, title: str) -> Tuple[str, str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–±—Ä–∏–∫–µ –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ_–Ω–∞–∑–≤–∞–Ω–∏–µ, —Ñ–∞–±—Ä–∏–∫–∞, –∞—Ä—Ç–∏–∫—É–ª)
        """
        factory = ""
        article = ""
        clean_title = title
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–±—Ä–∏–∫ –∏ –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        patterns = [
            # Givaudan Premium
            r',\s*(Givaudan Premium)\s*$',
            # SELUZ
            r',\s*(SELUZ|Seluz)\s*$',
            # Argeville
            r',\s*(Argeville)\s*$',
            # Lz —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º
            r',\s*(Lz)\s+(\d+[\d\-T]*)\s*$',
            r',\s*(Lz)\s+(\d+[\d\-/\s]*)\s*$',
            # –ü—Ä–æ—Å—Ç–æ Lz
            r',\s*(Lz)\s*$',
            # –î—Ä—É–≥–∏–µ —Ñ–∞–±—Ä–∏–∫–∏
            r',\s*(Bin Tammam|EPS|Hamidi|Iberchem|LZ AG|MG Gulcicek|Reiha|LUZI|Luzi)\s*([^,]*?)\s*$'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, title, re.IGNORECASE)
            if match:
                factory = match.group(1)
                if len(match.groups()) > 1 and match.group(2):
                    article = match.group(2).strip()
                # –£–¥–∞–ª—è–µ–º –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ñ–∞–±—Ä–∏–∫—É –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è
                clean_title = re.sub(pattern, '', title, flags=re.IGNORECASE).strip()
                break
        
        return clean_title, factory, article

    def parse_title_and_brand(self, title: str) -> Tuple[str, str, str, str]:
        """
        –ü–∞—Ä—Å–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ, –∏–∑–≤–ª–µ–∫–∞—è –±—Ä–µ–Ω–¥, –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä–æ–º–∞—Ç–∞, —Ñ–∞–±—Ä–∏–∫—É –∏ –∞—Ä—Ç–∏–∫—É–ª
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–±—Ä–µ–Ω–¥, –Ω–∞–∑–≤–∞–Ω–∏–µ_–∞—Ä–æ–º–∞—Ç–∞, —Ñ–∞–±—Ä–∏–∫–∞, –∞—Ä—Ç–∏–∫—É–ª)
        """
        # –°–Ω–∞—á–∞–ª–∞ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–±—Ä–∏–∫–µ
        clean_title, factory, article = self.extract_factory_info(title)
        
        # –£–±–∏—Ä–∞–µ–º "(–º–æ—Ç–∏–≤)" –∏ –ø–æ–¥–æ–±–Ω—ã–µ –ø–æ–º–µ—Ç–∫–∏
        clean_title = re.sub(r'\s*\(–º–æ—Ç–∏–≤[^)]*\)\s*', ' ', clean_title).strip()
        clean_title = re.sub(r'\s+', ' ', clean_title)  # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        
        brand = ""
        perfume_name = clean_title
        
        # –ò—â–µ–º –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –≤ –Ω–∞—á–∞–ª–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        for known_brand in sorted(self.known_brands, key=len, reverse=True):
            pattern = rf'^{re.escape(known_brand)}\s+'
            if re.match(pattern, clean_title, re.IGNORECASE):
                brand = known_brand
                perfume_name = re.sub(pattern, '', clean_title, flags=re.IGNORECASE).strip()
                break
        
        # –ï—Å–ª–∏ –±—Ä–µ–Ω–¥ –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        if not brand:
            # –ü–∞—Ç—Ç–µ—Ä–Ω: "–ë—Ä–µ–Ω–¥ - –ù–∞–∑–≤–∞–Ω–∏–µ"
            dash_match = re.match(r'^([^-]+?)\s*-\s*(.+)$', clean_title)
            if dash_match:
                potential_brand = dash_match.group(1).strip()
                if len(potential_brand.split()) <= 3:  # –ë—Ä–µ–Ω–¥ –æ–±—ã—á–Ω–æ –Ω–µ –±–æ–ª–µ–µ 3 —Å–ª–æ–≤
                    brand = potential_brand
                    perfume_name = dash_match.group(2).strip()
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω: –ø–µ—Ä–≤—ã–µ 1-2 —Å–ª–æ–≤–∞ –∫–∞–∫ –±—Ä–µ–Ω–¥
            if not brand:
                words = clean_title.split()
                if len(words) >= 2:
                    # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–≤—ã–µ 2 —Å–ª–æ–≤–∞
                    potential_brand = ' '.join(words[:2])
                    if any(char.isupper() for char in potential_brand):
                        brand = potential_brand
                        perfume_name = ' '.join(words[2:]) if len(words) > 2 else words[-1]
                    else:
                        # –ü—Ä–æ–±—É–µ–º –ø–µ—Ä–≤–æ–µ —Å–ª–æ–≤–æ
                        brand = words[0]
                        perfume_name = ' '.join(words[1:])
        
        return brand, perfume_name, factory, article

    def create_unique_key(self, brand: str, name: str, factory: str, article: str) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è —Ç–æ–≤–∞—Ä–∞ —Å —É—á–µ—Ç–æ–º —Ñ–∞–±—Ä–∏–∫–∏
        """
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
        brand_norm = brand.lower().strip()
        name_norm = name.lower().strip()
        factory_norm = factory.lower().strip()
        article_norm = article.lower().strip()
        
        # –ö–ª—é—á –≤–∫–ª—é—á–∞–µ—Ç –±—Ä–µ–Ω–¥, –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ñ–∞–±—Ä–∏–∫—É (–Ω–æ –Ω–µ –∞—Ä—Ç–∏–∫—É–ª, —Ç–∞–∫ –∫–∞–∫ –æ–Ω –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ—Å—Ç–æ –Ω–æ–º–µ—Ä–æ–º –ø–∞—Ä—Ç–∏–∏)
        return f"{brand_norm}|{name_norm}|{factory_norm}"

    def parse_page(self, url: str) -> List[Dict[str, str]]:
        """–ü–∞—Ä—Å–∏—Ç –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞—Ç–∞–ª–æ–≥–∞"""
        soup = self.get_page_content(url)
        if not soup:
            return []
        
        perfumes = []
        product_links = soup.find_all('a', class_='product-title')
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {url}: {len(product_links)}")
        
        for link in product_links:
            try:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                title = link.get_text(strip=True)
                if not title:
                    continue
                
                # –ü–∞—Ä—Å–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                brand, perfume_name, factory, article = self.parse_title_and_brand(title)
                
                # URL —Ç–æ–≤–∞—Ä–∞
                product_url = link.get('href')
                if product_url:
                    if product_url.startswith('/'):
                        product_url = urljoin(self.base_url, product_url)
                
                # –ò—â–µ–º —Ü–µ–Ω—É
                price = ""
                price_element = None
                
                # –ò—â–µ–º —Ü–µ–Ω—É –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–∞—Ö
                current = link
                for _ in range(5):  # –ú–∞–∫—Å–∏–º—É–º 5 —É—Ä–æ–≤–Ω–µ–π –≤–≤–µ—Ä—Ö
                    current = current.parent
                    if not current:
                        break
                    
                    price_element = current.find(class_=re.compile(r'price'))
                    if price_element:
                        price = price_element.get_text(strip=True)
                        break
                
                perfume_info = {
                    'full_title': title,
                    'brand': brand,
                    'name': perfume_name,
                    'factory': factory,
                    'article': article,
                    'url': product_url,
                    'price': price,
                    'unique_key': self.create_unique_key(brand, perfume_name, factory, article)
                }
                
                perfumes.append(perfume_info)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–æ–≤–∞—Ä–∞: {e}")
                continue
        
        return perfumes

    def get_all_pages_urls(self) -> List[str]:
        """–ü–æ–ª—É—á–∞–µ—Ç URLs –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞"""
        catalog_url = f"{self.base_url}/perfume/"
        soup = self.get_page_content(catalog_url)
        if not soup:
            return [catalog_url]
        
        urls = [catalog_url]
        
        # –ò—â–µ–º –ø–∞–≥–∏–Ω–∞—Ü–∏—é
        pagination_selectors = [
            'nav.pagination a',
            '.pagination a',
            'a[href*="/perfume/page/"]',
            'a[href*="page="]'
        ]
        
        for selector in pagination_selectors:
            links = soup.select(selector)
            if links:
                for link in links:
                    href = link.get('href')
                    if href and '/perfume/' in href:
                        if href.startswith('/'):
                            href = urljoin(self.base_url, href)
                        if href not in urls:
                            urls.append(href)
                break
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü –∫–∞—Ç–∞–ª–æ–≥–∞: {len(urls)}")
        return sorted(urls)

    def parse_all_catalog(self) -> List[Dict[str, str]]:
        """–ü–∞—Ä—Å–∏—Ç –≤–µ—Å—å –∫–∞—Ç–∞–ª–æ–≥"""
        all_urls = self.get_all_pages_urls()
        all_perfumes = []
        unique_keys = set()
        
        for i, url in enumerate(all_urls, 1):
            logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é —Å—Ç—Ä–∞–Ω–∏—Ü—É {i}/{len(all_urls)}: {url}")
            
            page_perfumes = self.parse_page(url)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã (—Å —É—á–µ—Ç–æ–º —Ñ–∞–±—Ä–∏–∫–∏)
            for perfume in page_perfumes:
                unique_key = perfume['unique_key']
                if unique_key not in unique_keys:
                    unique_keys.add(unique_key)
                    all_perfumes.append(perfume)
                else:
                    logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {perfume['full_title']}")
            
            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            if i < len(all_urls):
                time.sleep(1)
        
        logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤: {len(all_perfumes)}")
        return all_perfumes

    def analyze_factories(self, perfumes: List[Dict[str, str]]) -> Dict:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ —Ñ–∞–±—Ä–∏–∫–∞–º"""
        factory_stats = {}
        brand_factory_combinations = {}
        
        for perfume in perfumes:
            factory = perfume.get('factory', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
            brand = perfume.get('brand', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π')
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–∞–±—Ä–∏–∫–∞–º
            if factory not in factory_stats:
                factory_stats[factory] = 0
            factory_stats[factory] += 1
            
            # –ö–æ–º–±–∏–Ω–∞—Ü–∏–∏ –±—Ä–µ–Ω–¥-—Ñ–∞–±—Ä–∏–∫–∞
            combo = f"{brand} | {factory}"
            if combo not in brand_factory_combinations:
                brand_factory_combinations[combo] = 0
            brand_factory_combinations[combo] += 1
        
        return {
            'factory_stats': dict(sorted(factory_stats.items(), key=lambda x: x[1], reverse=True)),
            'brand_factory_combinations': dict(sorted(brand_factory_combinations.items(), key=lambda x: x[1], reverse=True)),
            'total_factories': len([f for f in factory_stats.keys() if f != '–ù–µ —É–∫–∞–∑–∞–Ω–∞']),
            'products_with_factory': sum(1 for p in perfumes if p.get('factory'))
        }

    def save_to_json(self, filename: str = 'enhanced_perfumes_with_factories.json') -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON —Ñ–∞–π–ª"""
        if not self.perfumes:
            logger.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–±—Ä–∏–∫–∏
        factory_analysis = self.analyze_factories(self.perfumes)
        
        data = {
            'metadata': {
                'source': 'aroma-euro.ru',
                'catalog_url': f'{self.base_url}/perfume/',
                'parsing_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'total_count': len(self.perfumes),
                'parser_version': 'enhanced-factory-1.0',
                'factory_analysis': factory_analysis
            },
            'perfumes': self.perfumes
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            logger.info(f"–î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {filename}")
            
            # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ü–ê–†–°–ò–ù–ì–ê:")
            print(f"–í—Å–µ–≥–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(self.perfumes)}")
            print(f"–¢–æ–≤–∞—Ä–æ–≤ —Å —É–∫–∞–∑–∞–Ω–Ω–æ–π —Ñ–∞–±—Ä–∏–∫–æ–π: {factory_analysis['products_with_factory']}")
            print(f"–í—Å–µ–≥–æ —Ñ–∞–±—Ä–∏–∫: {factory_analysis['total_factories']}")
            
            print(f"\nüè≠ –¢–û–ü –§–ê–ë–†–ò–ö:")
            for factory, count in list(factory_analysis['factory_stats'].items())[:10]:
                print(f"  {factory}: {count} —Ç–æ–≤–∞—Ä–æ–≤")
            
            print(f"\nüîù –¢–û–ü –ö–û–ú–ë–ò–ù–ê–¶–ò–ô –ë–†–ï–ù–î-–§–ê–ë–†–ò–ö–ê:")
            for combo, count in list(factory_analysis['brand_factory_combinations'].items())[:10]:
                print(f"  {combo}: {count} —Ç–æ–≤–∞—Ä–æ–≤")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")

def main():
    parser = EnhancedFactoryParser()
    
    print("üöÄ –ó–∞–ø—É—Å–∫ —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ñ–∞–±—Ä–∏–∫...")
    print("üìç –°–∞–π—Ç: https://aroma-euro.ru/perfume/")
    print("üéØ –¶–µ–ª—å: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏–π, –±—Ä–µ–Ω–¥–æ–≤, —Ñ–∞–±—Ä–∏–∫ –∏ –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
    print("-" * 60)
    
    try:
        # –ü–∞—Ä—Å–∏–º –∫–∞—Ç–∞–ª–æ–≥
        parser.perfumes = parser.parse_all_catalog()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        parser.save_to_json()
        
        print("\n‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü–∞—Ä—Å–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()