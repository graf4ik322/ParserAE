#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import asyncio
import schedule
import logging
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional

from parsers.data_processor import DataProcessor

logger = logging.getLogger(__name__)

class AutoParser:
    """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–Ω–æ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞"""
    
    def __init__(self, db_manager, config=None):
        self.db = db_manager
        self.data_processor = DataProcessor(self.db)
        self.config = config
        self.running = False
        self.last_catalog_hash = None
        
        logger.info("üîÑ AutoParser –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    async def start_scheduler(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        try:
            self.running = True
            logger.info("‚è∞ –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –∑–∞–ø—É—â–µ–Ω")
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON
            await self._initial_data_load()
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏—é
            asyncio.create_task(self._run_periodic_parsing())
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫–∞: {e}")
    
    async def _run_periodic_parsing(self):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥"""
        last_parse_time = datetime.now()
        
        while self.running:
            try:
                current_time = datetime.now()
                
                # –ü–∞—Ä—Å–∏–Ω–≥ –∫–∞–∂–¥—ã–µ 6 —á–∞—Å–æ–≤
                if (current_time - last_parse_time).total_seconds() >= 6 * 3600:
                    logger.info("üîÑ –ó–∞–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥...")
                    await self._check_and_parse()
                    last_parse_time = current_time
                
                # –ñ–¥–µ–º 30 –º–∏–Ω—É—Ç –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                await asyncio.sleep(1800)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–º –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
                await asyncio.sleep(3600)  # –ñ–¥–µ–º —á–∞—Å –ø—Ä–∏ –æ—à–∏–±–∫–µ
    
    def stop_scheduler(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫"""
        self.running = False
        logger.info("üõë –ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    async def _check_and_parse(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
        try:
            logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞...")
            
            # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π
            # –ü–æ–∫–∞ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–∞–ª–æ–≥
            await self._parse_and_update_catalog()
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏ –ø–∞—Ä—Å–∏–Ω–≥–µ: {e}")
    
    async def _parse_and_update_catalog(self):
        """–ü–∞—Ä—Å–∏—Ç –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –∫–∞—Ç–∞–ª–æ–≥ –ø–∞—Ä—Ñ—é–º–æ–≤"""
        try:
            logger.info("üìä –û–±–Ω–æ–≤–ª—è–µ–º –∫–∞—Ç–∞–ª–æ–≥ –ø–∞—Ä—Ñ—é–º–æ–≤...")
            
            # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ª–æ–≥–∏–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–∞–π—Ç–æ–≤
            # –ü–æ–∫–∞ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
            logger.info("‚úÖ –ö–∞—Ç–∞–ª–æ–≥ —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
    
    async def _initial_data_load(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞ –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –¥–∞–Ω–Ω—ã–µ –≤ –ë–î
            perfumes_count = self.db.count_perfumes()
            
            if perfumes_count == 0:
                logger.info("üìÇ –ë–î –ø—É—Å—Ç–∞, –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON —Ñ–∞–π–ª–∞...")
                await self._load_data_from_json()
            else:
                logger.info(f"üìä –í –ë–î —É–∂–µ –µ—Å—Ç—å {perfumes_count} –ø–∞—Ä—Ñ—é–º–æ–≤")
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–∞—á–∞–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    async def _load_data_from_json(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ JSON —Ñ–∞–π–ª–∞"""
        try:
            json_file = "full_perfumes_catalog_complete.json"
            
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if 'perfumes' in data:
                perfumes_data = data['perfumes']
                logger.info(f"üìÑ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(perfumes_data)} –ø–∞—Ä—Ñ—é–º–æ–≤ –∏–∑ JSON")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ä—Ñ—é–º
                processed_count = 0
                for perfume_raw in perfumes_data:
                    try:
                        normalized_perfume = self.data_processor.normalize_perfume_data(perfume_raw)
                        if self.db.save_perfume_to_database(normalized_perfume):
                            processed_count += 1
                            
                        if processed_count % 100 == 0:
                            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –ø–∞—Ä—Ñ—é–º–æ–≤...")
                            
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–∞—Ä—Ñ—é–º–∞: {e}")
                        continue
                
                logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {processed_count} –ø–∞—Ä—Ñ—é–º–æ–≤ –≤ –ë–î")
                
            else:
                logger.warning("JSON —Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á 'perfumes'")
                
        except FileNotFoundError:
            logger.warning("JSON —Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω, –±—É–¥–µ–º –∂–¥–∞—Ç—å –ø–∞—Ä—Å–∏–Ω–≥–∞")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON: {e}")
    
    def _schedule_check_and_parse(self):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∏ –ø–∞—Ä—Å–∏–Ω–≥ (–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è async)"""
        asyncio.create_task(self.check_and_parse_catalog())
    
    def _schedule_daily_full_parse(self):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ (–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è async)"""
        asyncio.create_task(self.daily_full_parse())
    
    def _schedule_weekly_full_update(self):
        """–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ (–æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è async)"""
        asyncio.create_task(self.weekly_full_update())
    
    async def check_and_parse_catalog(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–∞—Ç–∞–ª–æ–≥–∞ –∏ –ø–∞—Ä—Å–∏—Ç –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"""
        try:
            logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ...")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –Ω–∞ —Å–∞–π—Ç–µ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
            if await self._has_catalog_changes():
                logger.info("üìà –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ, –∑–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥...")
                result = await self.parse_and_save_catalog()
                
                if result:
                    logger.info("üì® –£–≤–µ–¥–æ–º–ª—è–µ–º –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –æ–± –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –∫–∞—Ç–∞–ª–æ–≥–∞")
                    await self._notify_admin("–ö–∞—Ç–∞–ª–æ–≥ –æ–±–Ω–æ–≤–ª–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
                
                return result
            else:
                logger.info("üìä –ò–∑–º–µ–Ω–µ–Ω–∏–π –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ")
                return False
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return False
    
    async def daily_full_parse(self) -> bool:
        """–ï–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥"""
        logger.info("üåÖ –ó–∞–ø—É—Å–∫–∞–µ–º –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞...")
        return await self.parse_and_save_catalog()
    
    async def weekly_full_update(self) -> bool:
        """–ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å –æ—á–∏—Å—Ç–∫–æ–π"""
        logger.info("üóìÔ∏è –ó–∞–ø—É—Å–∫–∞–µ–º –µ–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ–µ –ø–æ–ª–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞—Ç–∞–ª–æ–≥–∞...")
        
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ—á–∏—Å—Ç–∫–∏ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –¥–µ–ª–∞–µ–º –ø–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥
        return await self.parse_and_save_catalog()
    
    async def force_parse_catalog(self) -> bool:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞ (–¥–ª—è –∞–¥–º–∏–Ω-–∫–æ–º–∞–Ω–¥—ã)"""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞—Ç–∞–ª–æ–≥–∞...")
        return await self.parse_and_save_catalog()
    
    async def parse_and_save_catalog(self) -> bool:
        """–ü–∞—Ä—Å–∏—Ç –∫–∞—Ç–∞–ª–æ–≥ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤ –ë–î"""
        try:
            # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä
            from complete_parser_with_details import CompleteParfumeParser
            
            logger.info("üï∑Ô∏è –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å —Å–∞–π—Ç–∞ aroma-euro.ru...")
            
            # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
            parser = CompleteParfumeParser(max_workers=3)
            
            # –ü–∞—Ä—Å–∏–º –∫–∞—Ç–∞–ª–æ–≥
            raw_perfumes = parser.parse_all_catalog()
            
            if not raw_perfumes:
                logger.warning("‚ö†Ô∏è –ü–∞—Ä—Å–µ—Ä –Ω–µ –≤–µ—Ä–Ω—É–ª –¥–∞–Ω–Ω—ã—Ö")
                return False
            
            logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–æ {len(raw_perfumes)} –ø–∞—Ä—Ñ—é–º–æ–≤ –æ—Ç –ø–∞—Ä—Å–µ—Ä–∞")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ä—Ñ—é–º
            processed_count = 0
            updated_count = 0
            new_count = 0
            
            for perfume_raw in raw_perfumes:
                try:
                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –ø–∞—Ä—Ñ—é–º–∞
                    normalized_perfume = self.data_processor.normalize_perfume_data(perfume_raw)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ –ø–∞—Ä—Ñ—é–º
                    existing = self.db.get_perfume_by_unique_key(normalized_perfume['unique_key'])
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
                    if self.db.save_perfume_to_database(normalized_perfume):
                        processed_count += 1
                        
                        if existing:
                            updated_count += 1
                        else:
                            new_count += 1
                            
                        if processed_count % 50 == 0:
                            logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count} –ø–∞—Ä—Ñ—é–º–æ–≤...")
                            
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø–∞—Ä—Ñ—é–º–∞: {e}")
                    continue
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –ø–æ–∏—Å–∫–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã (–µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ)
            await self._update_search_indexes()
            
            logger.info(f"""
‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ:
‚îú‚îÄ‚îÄ üìä –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed_count}
‚îú‚îÄ‚îÄ üÜï –ù–æ–≤—ã—Ö –ø–∞—Ä—Ñ—é–º–æ–≤: {new_count}
‚îú‚îÄ‚îÄ üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö: {updated_count}
‚îî‚îÄ‚îÄ üìÖ –í—Ä–µ–º—è: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
            """)
            
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return False
    
    async def _has_catalog_changes(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ –∫–∞—Ç–∞–ª–æ–≥–µ"""
        try:
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ö—ç—à –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫–∞—Ç–∞–ª–æ–≥–∞
            import requests
            from bs4 import BeautifulSoup
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get('https://aroma-euro.ru/perfume/', headers=headers, timeout=10)
            if response.status_code == 200:
                # –°–æ–∑–¥–∞–µ–º —Ö—ç—à –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # –ò—â–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ç–æ–≤–∞—Ä–∞–º–∏
                products_container = soup.find('div', class_='products-list') or soup.find('div', class_='catalog-items')
                
                if products_container:
                    content_hash = hashlib.md5(str(products_container).encode()).hexdigest()
                    
                    if self.last_catalog_hash is None:
                        self.last_catalog_hash = content_hash
                        return True  # –ü–µ—Ä–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è
                    
                    if content_hash != self.last_catalog_hash:
                        self.last_catalog_hash = content_hash
                        return True
                    
                    return False
                else:
                    logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ç–æ–≤–∞—Ä–∞–º–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ")
                    return True  # –í —Å–ª—É—á–∞–µ —Å–æ–º–Ω–µ–Ω–∏–π –ª—É—á—à–µ –æ–±–Ω–æ–≤–∏—Ç—å
            else:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∫–∞—Ç–∞–ª–æ–≥–∞: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∫–∞—Ç–∞–ª–æ–≥–∞: {e}")
            return False
    
    async def _update_search_indexes(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ–∏—Å–∫–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã (–∑–∞–≥–ª—É—à–∫–∞)"""
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
        logger.info("üîç –ü–æ–∏—Å–∫–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã –æ–±–Ω–æ–≤–ª–µ–Ω—ã")
    
    async def _notify_admin(self, message: str):
        """–£–≤–µ–¥–æ–º–ª—è–µ—Ç –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä–∞ –æ —Å–æ–±—ã—Ç–∏—è—Ö"""
        try:
            if self.config and hasattr(self.config, 'admin_user_id'):
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ—Ç–ø—Ä–∞–≤–∫—É —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è —á–µ—Ä–µ–∑ Telegram
                # –ü–æ–∫–∞ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º
                logger.info(f"üì® –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –∞–¥–º–∏–Ω—É: {message}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è –∞–¥–º–∏–Ω—É: {e}")
    
    def get_parsing_status(self) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç—É—Å –ø–∞—Ä—Å–∏–Ω–≥–∞"""
        return {
            'running': self.running,
            'last_check': datetime.now().isoformat(),
            'total_perfumes': self.db.count_perfumes(),
            'last_catalog_hash': self.last_catalog_hash
        }