#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import re
import logging
from typing import Dict, Any, Optional
from hashlib import md5

logger = logging.getLogger(__name__)

class DataProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Ñ—é–º–æ–≤"""
    
    def __init__(self, db_manager):
        self.db = db_manager
        
        # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ —Ñ–∞–±—Ä–∏–∫–∏ (–∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–µ—Ä–∞)
        self.known_factories = [
            'Bin Tammam', 'EPS', 'Givaudan', 'Givaudan Premium', 'Givaudan SuperLux',
            'Hamidi', 'Iberchem', 'LZ AG', 'Lz', 'LZ', 'MG Gulcicek', 'Reiha', 
            'Argeville', 'SELUZ', 'Seluz', 'LUZI', 'Luzi'
        ]
        
        logger.info("üîß DataProcessor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def normalize_perfume_data(self, raw_perfume: Dict[str, Any]) -> Dict[str, Any]:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–∞—Ä—Ñ—é–º–∞ —Å–æ–≥–ª–∞—Å–Ω–æ —Å—Ö–µ–º–µ –ë–î"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            brand = self._clean_text(raw_perfume.get('brand', ''))
            name = self._clean_text(raw_perfume.get('name', ''))
            full_title = self._clean_text(raw_perfume.get('full_title', ''))
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–µ—Ç–∞–ª–∏ –∏–∑ –ø–∞—Ä—Ñ—é–º–∞ —Å–Ω–∞—á–∞–ª–∞
            details = raw_perfume.get('details', {})
            if isinstance(details, str):
                details = {}
            
            # –ü–†–ò–û–†–ò–¢–ï–¢ 1: –ê—Ä—Ç–∏–∫—É–ª –∏–∑ –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–ö–û–î)
            article = details.get('article', '').strip()
            
            # –ü–†–ò–û–†–ò–¢–ï–¢ 2: –ï—Å–ª–∏ –∞—Ä—Ç–∏–∫—É–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –¥–µ—Ç–∞–ª—è—Ö, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è/URL
            if not article:
                article = self._extract_article(full_title, raw_perfume.get('url', ''))
                logger.debug(f"–ê—Ä—Ç–∏–∫—É–ª –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è/URL: '{article}'")
            else:
                logger.debug(f"–ê—Ä—Ç–∏–∫—É–ª –Ω–∞–π–¥–µ–Ω –≤ –¥–µ—Ç–∞–ª—è—Ö: '{article}'")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–±—Ä–∏–∫—É
            factory = self._normalize_factory(raw_perfume.get('factory', ''))
            factory_detailed = self._extract_factory_details(raw_perfume)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ü–µ–Ω—É
            price_str = str(raw_perfume.get('price', ''))
            price = self._extract_numeric_price(price_str)
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
            unique_key = self._create_unique_key(brand, name, factory)
            
            gender = self._normalize_gender(details.get('gender', ''))
            fragrance_group = self._normalize_fragrance_group(details.get('fragrance_group', ''))
            quality_level = self._normalize_quality_level(details.get('quality', ''))
            
            # URL
            url = raw_perfume.get('url', '')
            if url and not url.startswith('http'):
                url = f"https://aroma-euro.ru{url}"
            
            normalized = {
                'article': article,
                'unique_key': unique_key,
                'brand': brand,
                'name': name,
                'full_title': full_title,
                'factory': factory,
                'factory_detailed': factory_detailed,
                'price': price,
                'price_formatted': price_str,
                'currency': 'RUB',
                'gender': gender,
                'fragrance_group': fragrance_group,
                'quality_level': quality_level,
                'url': url
            }
            
            return normalized
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö –ø–∞—Ä—Ñ—é–º–∞: {e}")
            logger.error(f"Raw data: {raw_perfume}")
            raise
    
    def _clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        if not text:
            return ''
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –ø–µ—Ä–µ–≤–æ–¥—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'\s+', ' ', str(text))
        text = text.strip()
        
        # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –≤—ã–∑–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã
        text = text.replace('\x00', '')
        
        return text
    
    def _extract_article(self, full_title: str, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä—Ç–∏–∫—É–ª –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è –∏–ª–∏ URL"""
        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞—Ä—Ç–∏–∫—É–ª –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ (–æ–±—ã—á–Ω–æ –≤ —Å–∫–æ–±–∫–∞—Ö –∏–ª–∏ –≤ –∫–æ–Ω—Ü–µ)
        article_patterns = [
            r'\b([A-Z]{2,}\d{3,})\b',  # –ë—É–∫–≤—ã + —Ü–∏—Ñ—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, TF001)
            r'\b(\d{4,})\b',           # –ü—Ä–æ—Å—Ç–æ —Ü–∏—Ñ—Ä—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 1234)
            r'\[([A-Z0-9\-]+)\]',      # –í –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö
            r'\(([A-Z0-9\-]+)\)',      # –í –∫—Ä—É–≥–ª—ã—Ö —Å–∫–æ–±–∫–∞—Ö
        ]
        
        for pattern in article_patterns:
            match = re.search(pattern, full_title)
            if match:
                return match.group(1)
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ URL
        if url:
            url_match = re.search(r'/([A-Z0-9\-]+)/?$', url.upper())
            if url_match:
                return url_match.group(1)
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∞—Ä—Ç–∏–∫—É–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö—ç—à–∞
        hash_source = f"{full_title}_{url}"
        article = 'GEN' + md5(hash_source.encode()).hexdigest()[:6].upper()
        
        return article
    
    def _normalize_factory(self, factory: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ —Ñ–∞–±—Ä–∏–∫–∏"""
        if not factory:
            return ''
        
        factory_clean = self._clean_text(factory)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–º —Ñ–∞–±—Ä–∏–∫–∞–º
        for known_factory in self.known_factories:
            if known_factory.lower() in factory_clean.lower():
                return known_factory
        
        return factory_clean
    
    def _extract_factory_details(self, raw_perfume: Dict[str, Any]) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–±—Ä–∏–∫–µ"""
        details = raw_perfume.get('details', {})
        if isinstance(details, dict):
            factory_detailed = details.get('factory_detailed', '')
            if factory_detailed:
                return self._clean_text(factory_detailed)
        
        return ''
    
    def _extract_numeric_price(self, price_str: str) -> float:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ–≤—É—é —Ü–µ–Ω—É –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        if not price_str:
            return 0.0
        
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, —Ç–æ—á–µ–∫ –∏ –∑–∞–ø—è—Ç—ã—Ö
        price_clean = re.sub(r'[^\d.,]', '', str(price_str))
        
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏
        price_clean = price_clean.replace(',', '.')
        
        try:
            return float(price_clean)
        except (ValueError, TypeError):
            return 0.0
    
    def _create_unique_key(self, brand: str, name: str, factory: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–ª—é—á–∞
        brand_norm = re.sub(r'[^\w\s]', '', brand.lower().strip())
        name_norm = re.sub(r'[^\w\s]', '', name.lower().strip())
        factory_norm = re.sub(r'[^\w\s]', '', factory.lower().strip())
        
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á
        key_source = f"{brand_norm}_{name_norm}_{factory_norm}"
        key_hash = md5(key_source.encode()).hexdigest()
        
        return f"{brand[:3].upper()}_{key_hash[:8]}"
    
    def _normalize_gender(self, gender: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø–æ–ª –ø–∞—Ä—Ñ—é–º–∞"""
        if not gender:
            return ''
        
        gender_lower = gender.lower()
        
        if '–º—É–∂—Å–∫' in gender_lower or 'men' in gender_lower:
            return '–ú—É–∂—Å–∫–æ–π'
        elif '–∂–µ–Ω—Å–∫' in gender_lower or 'women' in gender_lower:
            return '–ñ–µ–Ω—Å–∫–∏–π'
        elif '—É–Ω–∏—Å–µ–∫—Å' in gender_lower or 'unisex' in gender_lower:
            return '–£–Ω–∏—Å–µ–∫—Å'
        
        return self._clean_text(gender)
    
    def _normalize_fragrance_group(self, fragrance_group: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –≥—Ä—É–ø–ø—É –∞—Ä–æ–º–∞—Ç–æ–≤"""
        if not fragrance_group:
            return ''
        
        # –°–ø–∏—Å–æ–∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –≥—Ä—É–ø–ø –∞—Ä–æ–º–∞—Ç–æ–≤
        standard_groups = {
            '—Ü–≤–µ—Ç–æ—á–Ω': '–¶–≤–µ—Ç–æ—á–Ω—ã–µ',
            '—Ü–∏—Ç—Ä—É—Å': '–¶–∏—Ç—Ä—É—Å–æ–≤—ã–µ', 
            '–¥—Ä–µ–≤–µ—Å–Ω': '–î—Ä–µ–≤–µ—Å–Ω—ã–µ',
            '—Å–≤–µ–∂': '–°–≤–µ–∂–∏–µ',
            '–≤–æ—Å—Ç–æ—á–Ω': '–í–æ—Å—Ç–æ—á–Ω—ã–µ',
            '–≥—É—Ä–º–∞–Ω': '–ì—É—Ä–º–∞–Ω—Å–∫–∏–µ',
            '—Ñ—É–∂–µ—Ä': '–§—É–∂–µ—Ä–Ω—ã–µ',
            '—à–∏–ø—Ä': '–®–∏–ø—Ä–æ–≤—ã–µ',
            '–∞–º–±—Ä': '–ê–º–±—Ä–æ–≤—ã–µ',
            '–º—É—Å–∫—É—Å': '–ú—É—Å–∫—É—Å–Ω—ã–µ'
        }
        
        fragrance_lower = fragrance_group.lower()
        
        for key, standard_name in standard_groups.items():
            if key in fragrance_lower:
                return standard_name
        
        return self._clean_text(fragrance_group)
    
    def _normalize_quality_level(self, quality: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —É—Ä–æ–≤–µ–Ω—å –∫–∞—á–µ—Å—Ç–≤–∞"""
        if not quality:
            return ''
        
        quality_lower = quality.lower()
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —É—Ä–æ–≤–Ω–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if '–ø—Ä–µ–º–∏—É–º' in quality_lower or 'premium' in quality_lower:
            return '–ü—Ä–µ–º–∏—É–º'
        elif '–ª—é–∫—Å' in quality_lower or 'lux' in quality_lower:
            return '–õ—é–∫—Å'
        elif '—Å—Ç–∞–Ω–¥–∞—Ä—Ç' in quality_lower or 'standard' in quality_lower:
            return '–°—Ç–∞–Ω–¥–∞—Ä—Ç'
        elif '—ç–∫–æ–Ω–æ–º' in quality_lower or 'econom' in quality_lower:
            return '–≠–∫–æ–Ω–æ–º'
        
        return self._clean_text(quality)
    
    def validate_perfume_data(self, perfume_data: Dict[str, Any]) -> bool:
        """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–∞—Ä—Ñ—é–º–∞ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º"""
        required_fields = ['article', 'unique_key', 'brand', 'name', 'url']
        
        for field in required_fields:
            if not perfume_data.get(field):
                logger.warning(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")
                return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –ø–æ–ª–µ–π
        if len(perfume_data['article']) > 50:
            logger.warning(f"–ê—Ä—Ç–∏–∫—É–ª —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {perfume_data['article']}")
            return False
        
        if len(perfume_data['brand']) > 100:
            logger.warning(f"–ë—Ä–µ–Ω–¥ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {perfume_data['brand']}")
            return False
        
        return True